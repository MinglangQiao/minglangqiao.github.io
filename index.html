<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="files/jemdoc.css" type="text/css" />
<title>Qiao, Minglang</title>
</head>
<body>

<div class="menu"> <a href="#home">Home</a> 
<a href="#publications">Publications</a> 
<a href="#projects">Projects</a>  
<a href="#awards">Awards</a> 
<a href="#teaching">Teaching</a>
<a href="https://minglangqiao.github.io/demo-coding/">Demo</a>
</div>

<a id="home" class="anchor"></a>
<div id="container"> 
<div class="container"> 
<div id="toptitle">
<h1>Minglang Qiao</h1>
</div>

<table class="imgtable"><tr><td>
<a href="./"><img src="./files/minglangqiao.jpg" alt="" height="200px" /></a>&nbsp;</td>
<td align="left"><p><a href="./"><font size="4">Minglang, Qiao</font></a><br />
<i>  Postdoctoral Researcher </i>
<br /><br />
<a href="http://www.buaamc2.net/">Multimedia Computing Towards Communications (MC2) Lab</a><br />
<!-- IRC 207<br /> -->
School of Electronics and Information Engineering, Beihang University<br />
Beijing, 100191, China<br />
<br />
<!-- Email: <i>minglangqiao@buaa.edu.cn; minglangqiao@gmail.com</i><br /> -->
Email: <i>minglangqiao@buaa.edu.cn</i><br />
[<a href="https://scholar.google.com/citations?user=ETn_gGsAAAAJ&hl=en&oi=ao" target="_blank">Google Scholar</a>]
[<a href="https://github.com/MinglangQiao" target="_blank">Github</a>]
</p>
</td></tr>

</table>

<!-- <br>
My research interests include computer vision and perceptual video coding. Here is my full <b><a href="https://www.dropbox.com/s/lnwerecbek378g7/CV_minglang_pm1109.pdf?dl=0">Curriculum Vitae (CV)</a></b>. -->

<h2>About Me</h2>
<p style="text-align:justify"> I am a Postdoctoral Researcher at the <a href="http://www.buaamc2.net/">Multimedia Computing Towards Communications (MC2) Lab</a>, <a href="https://ev.buaa.edu.cn/">Beihang University</a>, China, collaborate with <a href="https://scholar.google.com/citations?user=JdhDuXAAAAAJ&hl=en&oi=ao">Prof. Mai Xu</a>. <br><br>

My research interests focus on low-level vision, including quality enhancement, quality assessment, human attention modeling, salient object detection and their applications on perceptual video coding.<br><br>

I obtained Ph.D. in Communications and Information Engineering at <a href="https://ev.buaa.edu.cn/">Beihang University</a> in 2024, supervised by <a href="https://scholar.google.com/citations?user=JdhDuXAAAAAJ&hl=en&oi=ao">Prof. Mai Xu</a>.
Previously, I obtained my B.Sc. degree in 2018 at Beihang University, P.R. China.
</p>

<!-- <h2>News</h2>
<ul>
<li>One paper is submmited to <b>IEEE Trans. TPAMI</b> 2021 [<a href= "https://www.aaai.org/AAAI21Papers/AAAI-2900.WangX.pdf">Paper</a>] [<a href= "https://github.com/XiaofeiWang2018/DR">Code</a>].</li>
<li>One paper is accepted to <b>ECCV</b> 2020 <font color="red"><b>(early accept)</b></font> [<a href= "https://link.springer.com/content/pdf/10.1007%2F978-3-030-59722-1_60.pdf">Paper</a>] [<a href= "https://github.com/XiaofeiWang2018/DeepGF">Code</a>].</li>
<li>One paper is accepted to <b>IEEE Trans. TMM</b> 2019 [<a href= "https://link.springer.com/content/pdf/10.1007%2F978-3-030-32239-7_47.pdf">Paper</a>] [<a href= "https://github.com/XiaofeiWang2018/patho-gan">Code</a>].</li>
<li>One paper is accepted to  <b>ECCV</b>. [<a href= "https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8756196&tag=1">Paper</a>] </li>
<li>One paper is accepted to <b>IEEE Trans. TPAMI</b> 2019 [<a href= "https://openaccess.thecvf.com/content_CVPR_2019/papers/Li_Attention_Based_Glaucoma_Detection_A_Large-Scale_Database_and_CNN_Model_CVPR_2019_paper.pdf">Paper</a>] .</li>
</ul>  -->

<!-- <a id="news" class="achor"></a>
<h2>News</h2>
<li> One paper is accepted to CVPR 2022 workshop. <a href="https://arxiv.org/pdf/2204.09924.pdf">[Paper]</a> [<a href= "https://github.com/ryanxingql/winner-ntire22-vqe">Homepage</a>] </li>
<li> We won the <font size="4" color="red"> 1st, 1st and 2nd </font> Place on three tracks of the Video Super-Resolution and Enhancement Challenge at the NTIRE workshop in CVPR 2022. 
    <a href="https://arxiv.org/abs/2204.09314">[Report]</a> <a href="https://mp.weixin.qq.com/s/8NHhFtJrmm7kTUf-QjHk6Q">[Blog]</a> <br> -->


<a id="publications" class="achor"></a>
<h2>Selected Publications</h2>

<table class="imgtable">

<tr>
  <td><img class="proj_thumb" src="./papers/ijcv21.png" alt=""/>&nbsp;</td>
  <td>
  <p class="pub_title">Joint learning of audio–visual saliency prediction and sound source localization on multi-face videos</p>
  <p class="pub_author"><u><b>Minglang Qiao</b></u>,&nbsp; Yufan Li,&nbsp; Mai Xu,&nbsp; Xin Deng, &nbsp; Bin Li, &nbsp; Weiming Hu and Ali Borji.<br>
  International Journal of Computer Vision </i> (<b>IJCV</b>), 2024. <br>  
  [<a href= "https://link.springer.com/article/10.1007/s11263-023-01950-3">Paper</a>] [<a href= "https://github.com/MinglangQiao/MVVA-Database">Code and Dataset</a>]
  </p> </td>
</tr>

<tr>
  <td><img class="proj_thumb" src="./papers/pami24.png" alt=""/>&nbsp;</td>
  <td>
  <p class="pub_title">HyperSOR: context-aware graph hypernetwork for salient object ranking</p>
  <p class="pub_author"><u><b>Minglang Qiao</b></u>,&nbsp; Mai Xu,&nbsp; Lai Jiang,&nbsp; Peng Lei, &nbsp; Shijie Wen, &nbsp; Yunjin Chen and Leonid Sigal.<br>
    IEEE Transactions on Pattern Analysis and Machine Intelligence </i> (<b>TPAMI</b>), 2024. <br>  
  [<a href= "https://ieeexplore.ieee.org/document/10443257">Paper</a>] [<a href= "https://github.com/MinglangQiao/SalSOD">Dataset</a>]
  </p> </td>
</tr>


<tr>
  <td><img class="proj_thumb" src="./papers/acmmmw24.png" alt=""/>&nbsp;</td>
  <td>
  <p class="pub_title">MT-VQA: A Multi-task Approach for Quality Assessment of Short-form Videos</p>
  <p class="pub_author">Shijie Wen,&nbsp; <u><b>Minglang Qiao<sup>✉</sup></b></u>,&nbsp; Lai Jiang,&nbsp; Mai Xu, &nbsp; Xin Deng, &nbsp; Shengxi Li.
  (<sup>✉</sup> Corresponding author)
    <br>
    ACM International Conference on Multimedia, QoEVMA Workshop </i> (<b>ACM MMW</b>), 2024. <br>  
    <b>This paper received the Best Paper Award.</b> 
  [<a href= "https://dl.acm.org/doi/10.1145/3689093.3689181">Paper</a>]
  </p> </td>
</tr>


<!-- <tr>
    <td><img class="proj_thumb" src="./papers/nt22_workshop.png" alt=""/>&nbsp; </td>
    <td>
    <p class="pub_title"> Progressive Training of A Two-Stage Framework for Video Restoration </p>
    <p class="pub_author">Meisong Zheng*,&nbsp; Qunliang Xing*,&nbsp; <u><b>Minglang Qiao*</b></u>,&nbsp;Mai Xu,&nbsp; Lai Jiang,&nbsp; Huaida Liu,&nbsp; Ying Chen. (* denotes equal contribution)<br>
      IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (<b>CVPRW</b>), 2022. <br> 
    [<a href= "https://github.com/ryanxingql/winner-ntire22-vqe">Homepage</a>] [<a href= "https://arxiv.org/pdf/2204.09924.pdf">Paper</a>]
    </p> </td>
</tr> -->

<!-- <tr>
  <td><img class="proj_thumb" src="./papers/nt22_stereo.png" alt=""/>&nbsp; </td>
  <td>
  <p class="pub_title"> NTIRE 2022 Stereo Image Super-Resolution Challenge </p>
  <p class="pub_author">Longguang Wang,&nbsp; Yulan Guo,&nbsp; Yingqian Wang,&nbsp;...,&nbsp; <u> <b>Minglang Qiao</b></u>,&nbsp; Zhenyu Guan,&nbsp;....<br>
    This challenge is a part of the NTIRE workshop in conjunction with <b>CVPR 2022</b>. <br> 
  [<a href= "https://github.com/The-Learning-And-Vision-Atelier-LAVA/Stereo-Image-SR/tree/NTIRE2022">Homepage</a>] [<a href= "https://arxiv.org/pdf/2204.09197.pdf">Report</a>]
  </p> </td>
</tr> -->

<tr>
  <td><img class="proj_thumb" src="./papers/NTIRE_22_enhance.jpg" alt=""/>&nbsp; </td>
  <td>
  <p class="pub_title"> NTIRE 2022 Challenge on Super-Resolution and Quality Enhancement of Compressed Video </p>
  <p class="pub_author">Ren Yang,&nbsp;Radu Timofte,&nbsp; Meisong Zheng,&nbsp;Qunliang Xing,&nbsp; <u> <b>Minglang Qiao</b></u>,&nbsp; Mai Xu,&nbsp;....<br>
    This challenge is a part of the NTIRE workshop in conjunction with CVPR 2022. <br>  <b>Two Champions and One Runner-up</b>. <br> 
  [<a href= "https://github.com/RenYang-home/NTIRE22_VEnh_SR">Homepage</a>] [<a href= "https://openaccess.thecvf.com/content/CVPR2022W/NTIRE/papers/Yang_NTIRE_2022_Challenge_on_Super-Resolution_and_Quality_Enhancement_of_Compressed_CVPRW_2022_paper.pdf">Report</a>] [<a href= "https://github.com/ryanxingql/winner-ntire22-vqe">Code</a>]
  </p> </td>
</tr>

<tr>
  <td><img class="proj_thumb" src="./papers/tmm20.PNG" alt=""/>&nbsp; </td>
  <td>
  <p class="pub_title">Viewport-Dependent Saliency Prediction in 360° Video</p>
  <p class="pub_author"><u><b>Minglang Qiao</b></u>,&nbsp;Mai Xu,&nbsp;Zulin Wang and Ali Borji.<br>
  IEEE Transactions on Multimedia</i> (<b>TMM</b>), 2020.<br> 
  [<a href= "https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9072511">Paper</a>] [<a href= "https://github.com/MinglangQiao/EM_Database">Dataset</a>]
  </p> </td>
</tr>

<tr>
<td><img class="proj_thumb" src="./papers/eccv20.png" alt=""/>&nbsp; </td>
<td>
<p class="pub_title">Learning to Predict Salient Faces: A Novel Visual-Audio Saliency Model</p>
<p class="pub_author"><u><b>Minglang Qiao* </b></u>,&nbsp;Yufan Liu*,&nbsp;Mai Xu,&nbsp;Bing Li,&nbsp;Weiming Hu and Ali Borji&nbsp. (* denotes equal contribution)<br>
Proceedings of the European Conference on Computer Vision </i> (<b>ECCV</b>), 2020. <br> 
[<a href= "https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123650409.pdf">Paper</a>] [<a href= "https://github.com/MinglangQiao/MVVA-Database">Dataset</a>]
</p> </td>
</tr>


<tr>
  <td><img class="proj_thumb" src="./papers/icassp24.png" alt=""/>&nbsp; </td>
  <td>
  <p class="pub_title">Saliency prediction of sports videos: A large-scale database and a self-adaptive approach</p>
  <p class="pub_author"><u><b>Minglang Qiao</b></u>,&nbsp; Mai Xu,&nbsp; Shijie Wen,&nbsp; Lai Jiang,&nbsp;Shengxi Li,&nbsp; Tao Xu,&nbsp; Yunjin Chen and Leonid Sigal. <br>
    IEEE International Conference on Acoustics, Speech and Signal Processing </i> (<b>ICASSP</b>), 2024. <br> 
  [<a href= "https://ieeexplore.ieee.org/abstract/document/10446481">Paper</a>] [<a href= "https://github.com/MinglangQiao/Sports_saliency">Code and Dataset</a>]
  </p> </td>
  </tr>

<tr>
  <td><img class="proj_thumb" src="./papers/tcsvt23.png" alt=""/>&nbsp;</td>
  <td>
  <p class="pub_title">Saliency prediction on mobile videos: A fixation mapping-based dataset and a transformer approach</p>
  <p class="pub_author">Shijie Wen,&nbsp;  Li Yang, &nbsp; Mai Xu, &nbsp; <u><b>Minglang Qiao</b></u>, &nbsp; Tao Xu and Lin Bai.<br>
  IEEE Transactions on Circuits and Systems for Video Technology </i> (<b>TCSVT</b>), 2023. <br>
  [<a href= "https://ieeexplore.ieee.org/abstract/document/10360106">Paper</a>] [<a href= "https://github.com/wenshijie110/MVFormer">Dataset</a>]
  </p> </td>
</tr>


<tr>
<td><img class="proj_thumb" src="./papers/pami18.png" alt=""/>&nbsp;</td>
<td>
<p class="pub_title">Predicting Head Movement in Panoramic Video: A Deep Reinforcement Learning Approach</p>
<p class="pub_author">Mai Xu,&nbsp;Yuhang Song,&nbsp;Jianyi Wang, <u><b>Minglang Qiao</b></u>, Liangyu Huo and Zulin Wang.<br>
  IEEE Transactions on Pattern Analysis and Machine Intelligence</i> (<b>TPAMI</b>), 2018.<br>
[<a href= "https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8418756">Paper</a>] [<a href= "https://github.com/YuhangSong/DHP">Code</a>] [<a href= "https://github.com/YuhangSong/DHP">Dataset</a>]
</p> </td>
</tr>





</table>

<!------------------------- Awards ------------------------->
<a id="awards" class="achor"></a>
<h2>Awards</h2> 
<ul>
<li> <a href= "https://mp.weixin.qq.com/s/8NHhFtJrmm7kTUf-QjHk6Q">Two Championships and One Runner-up in NTIRE 2022 Challenge on Super-Resolution and Quality Enhancement of Compressed Video</a>. 2022 [<a href= "./files/ntire22.png">Certificate</a>] </li>
<li> <a href= "https://naic.datafountain.cn/#/competitions?id=643">Champion of the 4th National Artificial Intelligence Competition in the "AI + Video Quality Assessment" track</a>. 2023 </li>
<li> <a href= "https://mp.weixin.qq.com/s/GNn_uyn2i0V9zuKqGeqaDA">Beihang Top-10 PhD Students Award</a>. 2024 </li>
<li> Outstanding Doctoral Dissertation of Beihang University. 2024 </li>
<li> Excellent Graduate of Beihang University. 2024 </li>
<li> <a href="https://www.nuedc-training.com.cn/index/news/details/new_id/19">National <b>1st Prize</b> in National Undergraduate Electronics Design Contest</a>. (Top 2.4%, among 14, 400+ teams). 2017 [<a href= "./files/diansai.jpg">Certificate</a>] </li> 
<li>National Encouragement Scholarship, P.R. China. 2017 [<a href= "./files/guoni2017.jpg">Certificate</a>] </li>
<li>Outstanding Science and Technology Scholarship of Beihang University. 2017 [<a href= "./files/keji1.jpg">Certificate</a>] </li>
<li>Admission Scholarship of Beihang University for First-year Postgraduate Student. 2018 </li>
<!-- <li>First Class of Postgraduate Scholarship in Beihang University </li> -->
<!-- <b>Other xx awards, including:</b> -->
<!-- <li>First Prize on the 26th "Fengru Cup" Innovation Contest (The top innovation competition in Beihang University) [<a href= "./files/fengru1.jpg">Certificate</a>] </li> -->
<!-- <li>Second Prize on the 27th "Fengru Cup" Innovation Contest [<a href= "./files/fengru2.jpg">Certificate</a>] </li> -->
<!-- <li>Second Prize on 8th national “Blue Bridge Cup” Programming Contest [<a href= "./files/lanqiao_8th.jpg">Certificate</a>]</li> -->
<!-- <li> </li> -->

</ul>



<!------------------------- projects --------------------------->
<a id="projects" class="achor"></a>
<h2>Projects</h2>
See more <b><a href= "https://xiaofeiwang2018.github.io/cv.pdf">details</a></b> of my projects.
<ul>
<li><b>Researches on Perceptual Video Coding </b> <br>
  Research on QoE-Oriented Perceptual Video Coding Technology with <a href= "https://www.taobao.com/"> Alibaba Cloud </a> (<a href= "https://damo.alibaba.com/air/?lang=en"> Alibaba Innovative Research Programme </a>, work with <a href= "https://scholar.google.com/citations?user=CaoMb2AAAAAJ&hl=en&oi=ao"> Yunjin Chen </a> ), 2021 - Present &nbsp; <br />
  QoE-Oriented Transcoding for E-Commerce Images on <a href= "https://www.taobao.com/">Taobao</a> of <a href= "https://www.alibaba.com/">Alibaba</a> (<a href= "https://damo.alibaba.com/air/?lang=en"> Alibaba Innovative Research Programme </a>, 2020 - 2021 <br /> 
  <!-- , <a href= "xxx">See demo</a>) -->
  Perceptual Video Coding of Live Video with <a href= "https://www.immomo.com/">Momo Corporation</a> (listed company), 2019 - 2020 &nbsp; 
  <!-- (<a href= "xxx">See video</a>) -->
</li>
</ul>
<ul>

<li><b>Researches on Human Attention Prediction</b><br>
   Deepvs: A Deep Learning Based Video Saliency Prediction Approach, 2017-2018, [<a href= "https://openaccess.thecvf.com/content_ECCV_2018/papers/Lai_Jiang_DeepVS_A_Deep_ECCV_2018_paper.pdf">Paper</a>] <br />
   Predicting Head Movement in Panoramic Video: A Deep Reinforcement Learning Approach, 2017 - 2018 [<a href= "https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8418756">Paper</a>]
  </li>
</ul>
<ul>
<!-- (<b>3rd student author</b>)<br> -->

<li><b>Researches on Multi-Task Learning </b> <br>
    Viewport-Dependent Saliency Prediction in 360° Video, 2018-2019 [<a href= "https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9072511">Paper</a>] <br>
    <!-- (<b>1st</b> Author) -->
    Joint Learning of Visual-Audio Saliency Prediction and Sound Source Localization on Multi-face Videos, 2020 - 2021 [<a href= "arxiv">Paper</a>] <br>
    <!-- (<b>1st</b> Author)
     <!-- </li> -->
  </ul>
<ul>

<li><b>Researches on Multi-Modal Learing </b> <br>
    Learning to Predict Salient Faces: A Novel Visual-Audio Saliency Model, 2019-2020 [<a href= "https://arxiv.org/pdf/2103.15438.pdf">Paper</a>] <br>
    </li>
</ul>





<!-- Teaching -->
<a id="teaching" class="achor"></a>
<h2>Teaching</h2> 
<ul>
<li>Teaching Assistant & Tutor: <b>Introduction to Machine Learning</b>, Beihang University (Fall 2021) </li>
<li>Teaching Assistant & Tutor:  <b>Comprehensive Innovation: Digital Communications</b>, Beihang University (Fall 2021) </li>
</ul>

<!-- <a id="demo" class="anchor"></a>
<h2>Demo</h2> 
See demos of my projects from  <a href= "https://minglangqiao.github.io/demo-coding/">[here]</a> -->

<!-- <h2 id="直接使用html-5-video-tag">直接使用HTML 5 video tag-xx</h2> -->
<!-- <video width="560" height="315" src="https://media.w3.org/2010/05/sintel/trailer.mp4" controls="controls" poster="https://media.w3.org/2010/05/sintel/poster.png">
your browser does not support the  HTML5 Video element
</video> -->

</ul>

<div id="footer">
</div>

</div>
</div>
<script type="text/javascript" src="//rf.revolvermaps.com/0/0/8.js?i=5kc4n7bl6dv&amp;m=0&amp;c=ff0000&amp;cr1=ffffff&amp;f=arial&amp;l=33" async="async"></script>
</body>
</html>
